[
  {
    "id": 43846,
    "summary": "Race condition with NIO connector parsing chunked response",
    "description": "The problem seems to relate to parsing the body content when the **Transfer-\nEncoding: chunked** header is present.  It appears that the chunk length gets\ncorrupted under load and the client is unable to parse the chunk out of the \nresponse body.\n\nWhen the NIO connector parameter **socket.appWriteBufSize** is set to a value \nlarger than the total response body, the error condition does not occur.\n\nOne might succesfully argue that this is proper performance tuning.  The Tomcat \ndocuments point out that to scale a large number of long held connections, the \nbuffer sizes may need to be less than the response body (the memory footprint \nwould be quite large otherwise).\n\nCould there be a race condition involving the response buffering code?  \n\nI have confirmed this behavior on both JDKs 1.5 and 1.6 on both Windows 2003 \nand Linux.\n\nApache Bench does not appear to fully parse the response so it will not be \nhelpful in reproducing the issue.   The Grinder framework does.  I am including \nthe Grinder scripts so that the issue may be reproduced.",
    "creation_ts": "2007-11-12T09:08:54Z",
    "fixes": [
      43846
    ],
    "comments": [
      "Created attachment 21114\nJython/Grinder script\n\nJython script referenced from grinder properties file.\t This script does most\nof the interaction with the Tomcat server.  It is configured via a grinder\nproperties file.",
      "Created attachment 21115\nGrinder properties file\n\nUse this file as a starting point for your Grinder setup.  This defines the\nnumber of threads, etc. to configure the test client.",
      "Created attachment 21116\nReponse generator servlet\n\nThis is a very simple Java servlet.  It generates a reponse body >8K.  This\nsomewhat larger response seems to render with Transfer-Encoding: chunked rather\nthan a Content-Length header.  This is what we want because the smaller\nresponse bodies seem to work OK.  In the real world responses larger than 8K\nare the norm.",
      "Thank you, I will take a look.\nFilip",
      "I'm unable to get your grinder scripts to work.\nThere are several errors that happen, for one, random is not available on a\nclean download of grinder.\n\nwhat would be helpful, is if you could create a test case, that I can run\nwithout trying to figure out grinder (sorry I'm a newbie to this) for most of a day.\n\nthanks\nFilip",
      "Created attachment 21123\nUse this Jython script instead\n\nUse this script instead of the first one attached.   Sorry for the trouble\nFilip.",
      "My apolgies Filip.   I've attached an updated Jython script.  This one does not \ndepend on random.",
      "I'm able to reproduce the problem in the connector using a JMeter script.\nThe error doesn't exist in the previous trunk connector, now in sandbox\nhttp://svn.apache.org/viewvc/tomcat/sandbox/gdev6x/\n\nThere are features in that branch not present in current release. I will look\ninto the option of porting the NIO enhancements from that branch to 6.0.x\n\nFilip",
      "I've created a patch for 6.0.x branch (a port from the sandbox)\nhttp://people.apache.org/~fhanik/patches/apache-tomcat-6.0.x-niofix.zip\n\nfeel free to try it out, and let me know the feedback\n\nFilip",
      "I've run a series of tests of various kinds and it appears that this issue is \nfixed in the patched version.   Would this fix going into a 6.0.15 release?",
      "Patch has been added to 6.0.x and will go out with 6.0.16 next release.\nThanks for the feedback."
    ]
  },
  {
    "id": 58373,
    "summary": "Data race on field org.apache.catalina.core.StandardContext.applicationEventListenersObjects",
    "description": "Reported by RV-Predict (a dynamic race detector) when running the test suite:\nData race on field org.apache.catalina.core.StandardContext.applicationEventListenersObjects: {{{\n    Concurrent read in thread T204 (locks held: {Monitor@424a8381})\n ---->  at org.apache.catalina.core.StandardContext.getApplicationEventListeners(StandardContext.java:1155)\n        at org.apache.catalina.core.StandardContext.fireRequestDestroyEvent(StandardContext.java:5920)\n        at org.apache.catalina.connector.CoyoteAdapter.asyncDispatch(CoyoteAdapter.java:282)\n        at org.apache.coyote.http11.AbstractHttp11Processor.asyncDispatch(AbstractHttp11Processor.java:1709)\n        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:651)\n        at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:277)\n        - locked Monitor@424a8381 at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:259) \n        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n    T204 is created by T202\n        at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:1010)\n\n    Concurrent write in thread T200 (locks held: {Monitor@42766493})\n ---->  at org.apache.catalina.core.StandardContext.setApplicationEventListeners(StandardContext.java:1161)\n        at org.apache.catalina.core.StandardContext.listenerStop(StandardContext.java:4825)\n        at org.apache.catalina.core.StandardContext.stopInternal(StandardContext.java:5390)\n        at org.apache.catalina.util.LifecycleBase.stop(LifecycleBase.java:232)\n        - locked Monitor@42766493 at org.apache.catalina.util.LifecycleBase.stop(LifecycleBase.java:n/a) \n        at org.apache.catalina.core.ContainerBase$StopChild.call(ContainerBase.java:1424)\n    T200 is created by T199\n        at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:1010)\n}}}",
    "creation_ts": "2015-09-12T01:30:39Z",
    "fixes": [
      58373
    ],
    "comments": [
      "Fixed in trunk and 8.0.x for 8.0.27 onwards."
    ]
  },
  {
    "id": 65106,
    "summary": "ConfigFileLoader cannot properly handle file url running with SecurityManager on openjdk 1.8",
    "description": "Created attachment 37718\nzip file with screens\n\nspring-boot 1.5.22 creates instance of Http11NioProtocol with certificate keystore file defined with file url. Images set-url.png, set-url2.png.\n\nWhen it reaches ConfigFileLoader, location is not absolute so it puts catalina_base before file url creating \"c:/tmp/catalina/file:/c:/tmp/my.jks\". Check if it is file throws AccessControlException (access denied (\"java.io.FilePermission\" \"C:\\tmp\\120\\a\\catalina\\file:\\C:\\tmp\\120\\key.jks\" \"read\")\n). And it is impossible to create such a policy for SecurityManager.\n- ConfigFileLoader.png\n- ConfigFileLoader.png\n- exception.png\n\ngetInputStream method can handle file url but when using SecurityManager under zulu, correto.\n\nOracle java 1.8 works correctly. SecurityManager has no complains about such weird path. Just openjdks have problem.\n\nFails on\n- zulu openjdk newer - zulu8.42.0.23-ca-jdk8.0.232-win_x64\n- correto 1.8.0_282\n\n\n```\n   public static InputStream getInputStream(String location) throws IOException {\n        File f = new File(location);\n        if (!f.isAbsolute()) {\n            f = new File(CATALINA_BASE_FILE, location);\n        }\n\n        if (f.isFile()) {\n            return new FileInputStream(f);\n        } else {\n            URI uri = getURI(location);\n\n            try {\n                URL url = uri.toURL();\n                return url.openConnection().getInputStream();\n            } catch (IllegalArgumentException var4) {\n                throw new IOException(sm.getString(\"configFileLoader.cannotObtainURL\", new Object[]{location}), var4);\n            }\n        }\n    }\n```",
    "creation_ts": "2021-01-26T12:56:58Z",
    "fixes": [
      65106
    ],
    "comments": [
      "Ok, after checking the javadoc, I can see that isAbsolute is a safe call (no security check) but isFile is not. Wrapping with a try/catch could be reasonable, however it would also hide the exception when it is legitimate and useful to have.",
      "I understand but the current state is that tomcat won't start.",
      "I am inching towards a WONTFIX, since the only real solution is to use URLs only. It would mean absolute file paths won't work, I believe, and this is not possible. The rest would be fine.\n\nI don't understand why \"And it is impossible to create such a policy for SecurityManager\", can you explain a bit more ?",
      "Caused by: java.io.IOException: Failed to load keystore type [JKS] with path [file:/C:/tmp/120/key.jks] due to [access denied (\"java.io.FilePermission\" \"C:\\tmp\\120\\a\\catalina\\file:\\C:\\tmp\\120\\key.jks\" \"read\")]\n\tat org.apache.tomcat.util.net.SSLUtilBase.getStore(SSLUtilBase.java:227)\n\n\nI have not found any way how to write such path to policy file so SecurityManager can accept it.\n\n    permission java.io.FilePermission \"file:${catalina.base}\", \"read\";\n    permission java.io.FilePermission \"${catalina.base}\", \"read\";\n    permission java.io.FilePermission \"file:${catalina.base}/\", \"read\";\n    permission java.io.FilePermission \"${catalina.base}/\", \"read\";\n    permission java.io.FilePermission \"file:${catalina.base}/-\", \"read\";\n    permission java.io.FilePermission \"${catalina.base}/-\", \"read\";\n    permission java.io.FilePermission \"file:${catalina.base}/*\", \"read\";\n    permission java.io.FilePermission \"${catalina.base}/*\", \"read\";\n    permission java.io.FilePermission \"C:/tmp/120/a/catalina\", \"read\";\n    permission java.io.FilePermission \"C:/tmp/120/a/catalina/\", \"read\";\n    permission java.io.FilePermission \"C:/tmp/120/a/catalina/-\", \"read\";\n    permission java.io.FilePermission \"C:/tmp/120/a/catalina/*\", \"read\";\n    permission java.io.FilePermission \"C:/tmp/120/a/catalina/file:/C:/tmp/120/key.jks\", \"read\";\n    permission java.io.FilePermission \"C:/tmp/120/a/catalina/file://C:/tmp/120/key.jks\", \"read\";\n    permission java.io.FilePermission \"C:/tmp/120/a/catalina/file:///C:/tmp/120/key.jks\", \"read\";\n    permission java.io.FilePermission \"C:\\\\tmp\\\\120\\\\a\\\\catalina\\\\file:\\\\C:\\\\tmp\\\\120\\\\key.jks\", \"read\";",
      "R\u00e9my, what if we added a\n\nif (\"name.startsWith(\"file:/\") {\n    ....\n}\nblock around the File and classloader case? Essentially short circuit to URI in that case for getResource() and getURI(). Does that help?",
      "That should be:\n\nif (*!*name...",
      "(In reply to Mark Thomas from comment #5)\n> R\u00e9my, what if we added a\n> \n> if (\"name.startsWith(\"file:/\") {\n>     ....\n> }\n> block around the File and classloader case? Essentially short circuit to URI\n> in that case for getResource() and getURI(). Does that help?\n\nI think that would work for the reporter but still fail for other URLs. This security check is annoying ...\nMaybe detect a URL scheme, like if there's ':' in the path and no '/' before it ?",
      "Hmm. Thinking...",
      "The best I can up with is if path starts with \"file:/\" or \"<protocol>://\" the code jumps directly to the URI handling. I'll work on a patch. I'm wondering how far to go optimizing the code. I'm thinking not far.",
      "(In reply to Mark Thomas from comment #9)\n> The best I can up with is if path starts with \"file:/\" or \"<protocol>://\"\n> the code jumps directly to the URI handling. I'll work on a patch. I'm\n> wondering how far to go optimizing the code. I'm thinking not far.\n\nOk. Yes, I don't think it needs to be super fast since this is for loading configuration resources.",
      "Fixed in:\n- 10.0.x for 10.0.2 onwards\n- 9.0.x for 9.0.43 onwards",
      "Any chance it will be fixed to 8.5?",
      "It was fixed shortly after in 8.5.63."
    ]
  },
  {
    "id": 43241,
    "summary": "ServletContext.getResourceAsStream()  does not follow API specs for Path",
    "description": "Say for example, you have a file style.css deployed in your context. The call to\nServletContext.getResourceAsStream(\"style.css\") returns an input stream. This is\nnot correct behavior.\n\nThe spec (2.3) says:\n\n> The path must be specified according to \n> the rules given in getResource. \n\ngetResource() says:\n\n> The path must begin with a \"/\" and is interpreted \n> as relative to the current context root.\n\nMy reading of these two things is that getResourceAsStream(\"style.css\") should\nreturn null, not an input stream to the file.\n\nI got bit on this because my app behavior changed (broke) when ran on the\ncurrent version of WebSphere.",
    "creation_ts": "2007-08-29T12:54:18Z",
    "fixes": [
      43241
    ],
    "comments": [
      "Created attachment 20919\ntest war\n\nAdding test war.",
      "Created attachment 20920\none way of fixing this\n\nHere's a simple patch which \"fixes\" the problem. getResourceAsStream can not\nthrow an Exception (according to the spec), so I just return null. \n\nI'm ambivalent about this patch. This may create problems for some people who\ndepend on the incorrect usage of this function. Plus, there may be a better\nsolution, such as always returning an input stream containing \"42\"",
      "Whilst I like the '42' idea, I am fairly sure not everyone else shares my sense\nof humour so null it will have to be.\n\nPatch applied to trunk and proposed for 5.5.x and 6.0.x.\n\nMany thanks for the patch.",
      "Fixed in 6.0.x",
      "Fixed in 5.5.x and will be included in 5.5.26 onwards.",
      "Fixed in 5.5.x and will be included in 5.5.26 onwards."
    ]
  },
  {
    "id": 65677,
    "summary": "InvalidMarkException in Http11InputBuffer.fill when socket read throws AsynchronousCloseException",
    "description": "When reading a CoyoteInputStream during a chunked Http/1.1\nPOST request, I've encountered a java.nio.InvalidMarkException\nunder certain conditions. Here's the stacktrace I observe:\n\njava.nio.InvalidMarkException: null\n\tat java.nio.Buffer.reset(Unknown Source)\n\tat java.nio.ByteBuffer.reset(Unknown Source)\n\tat java.nio.ByteBuffer.reset(Unknown Source)\n\tat o.a.coyote.http11.Http11InputBuffer.fill(Http11InputBuffer.java:813)\n\tat o.a.coyote.http11.Http11InputBuffer.access$400(Http11InputBuffer.java:42)\n\tat o.a.c.h.Http11InputBuffer$SocketInputBuffer.doRead(Http11InputBuffer.java:1172)\n\tat o.a.c.h.filters.ChunkedInputFilter.readBytes(ChunkedInputFilter.java:310)\n\tat o.a.c.h.filters.ChunkedInputFilter.parseChunkHeader(ChunkedInputFilter.java:338)\n\tat o.a.c.h.filters.ChunkedInputFilter.doRead(ChunkedInputFilter.java:164)\n\tat o.a.coyote.http11.Http11InputBuffer.doRead(Http11InputBuffer.java:249)\n\tat org.apache.coyote.Request.doRead(Request.java:640)\n\tat o.a.catalina.connector.InputBuffer.realReadBytes(InputBuffer.java:317)\n\tat o.a.catalina.connector.InputBuffer.checkByteBufferEof(InputBuffer.java:600)\n\tat o.a.catalina.connector.InputBuffer.read(InputBuffer.java:340)\n\tat o.a.c.connector.CoyoteInputStream.read(CoyoteInputStream.java:132)\n\nI currently assume that the thread reading the CoyoteInputStream is\ninterrupted because it's running within a Resilience4j TimeLimiter\nand the POST request takes too long. This should be ok though and\nI'd expect an InterruptedException or IOException in that case\nfrom the read call, but instead I get an InvalidMarkException.\n\nThis InvalidMarkException is thrown in the \"finally\"\nblock of this part in Http11InputBuffer.fill:\n\nbyteBuffer.mark();\ntry {\n    if (byteBuffer.position() < byteBuffer.limit()) {\n        byteBuffer.position(byteBuffer.limit());\n    }\n    byteBuffer.limit(byteBuffer.capacity());\n    SocketWrapperBase<?> socketWrapper = this.wrapper;\n    if (socketWrapper != null) {\n        nRead = socketWrapper.read(block, byteBuffer);\n    } else {\n        throw new CloseNowException(sm.getString(\"iib.eof.error\"));\n    }\n} finally {\n    // Ensure that the buffer limit and position are returned to a\n    // consistent \"ready for read\" state if an error occurs during in\n    // the above code block.\n    byteBuffer.limit(byteBuffer.position()).reset();\n}\n\nI've instrumented that part with more debug logs as follows (in\nparticular, for upcoming Tomcat versions, it might be good to add at\nleast the catch block to enhance debugging of such issues in the future):\n\nbyteBuffer.mark();\nif (log.isDebugEnabled()) {\n    log.debug(\"Set mark at position \" + byteBuffer.position());\n}\ntry {\n    if (byteBuffer.position() < byteBuffer.limit()) {\n        if (log.isDebugEnabled()) {\n            log.debug(\"Setting position to limit \" + byteBuffer.limit());\n        }\n        byteBuffer.position(byteBuffer.limit());\n    }\n    byteBuffer.limit(byteBuffer.capacity());\n    if (log.isDebugEnabled()) {\n        log.debug(\"Position before read \" + byteBuffer.position());\n    }\n    SocketWrapperBase<?> socketWrapper = this.wrapper;\n    if (socketWrapper != null) {\n        nRead = socketWrapper.read(block, byteBuffer);\n    } else {\n        throw new CloseNowException(sm.getString(\"iib.eof.error\"));\n    }\n} catch (Throwable e) {\n    if (log.isDebugEnabled()) {\n        log.debug(\"Encountered exception in read during fill, position=\" + byteBuffer.position(), e);\n    }\n    throw e;\n} finally {\n    // Ensure that the buffer limit and position are returned to a\n    // consistent \"ready for read\" state if an error occurs during in\n    // the above code block.\n    if (log.isDebugEnabled()) {\n        log.debug(\"Calling limit on byteBuffer with position \" + byteBuffer.position());\n    }\n    byteBuffer.limit(byteBuffer.position()).reset();\n}\n\nWhen that exception occurs, I see the following logs (before\nthat, the POST request was already running for about 30 seconds\nuntil the TimeLimiter kicked in and interrupted the thread):\n\n10:03:18.899\tBefore fill(): parsingHeader: [false], parsingRequestLine: [false], parsingRequestLinePhase: [0], parsingRequestLineStart: [0], byteBuffer.position(): [3313], byteBuffer.limit(): [3313], end: [2019]\n10:03:18.899\tSet mark at position 2019\n10:03:18.899\tPosition before read 2019\n10:03:18.942\tCalling limit on byteBuffer with position 3306\n\n10:03:18.942\tBefore fill(): parsingHeader: [false], parsingRequestLine: [false], parsingRequestLinePhase: [0], parsingRequestLineStart: [0], byteBuffer.position(): [3306], byteBuffer.limit(): [3306], end: [2019]\n10:03:18.942\tSet mark at position 2019\n10:03:18.942\tPosition before read 2019\n10:03:19.007\tCalling limit on byteBuffer with position 3306\n10:03:19.007\tReceived [500 <binary output>]\n\n10:03:19.007\tBefore fill(): parsingHeader: [false], parsingRequestLine: [false], parsingRequestLinePhase: [0], parsingRequestLineStart: [0], byteBuffer.position(): [3306], byteBuffer.limit(): [3306], end: [2019]\n10:03:19.007\tSet mark at position 2019\n10:03:19.007\tPosition before read 2019\n10:03:19.062\tCalling limit on byteBuffer with position 3306\n10:03:19.062\tReceived [500 <binary output>]\n\n10:03:19.063\tBefore fill(): parsingHeader: [false], parsingRequestLine: [false], parsingRequestLinePhase: [0], parsingRequestLineStart: [0], byteBuffer.position(): [3306], byteBuffer.limit(): [3306], end: [2019]\n10:03:19.063\tSet mark at position 2019\n10:03:19.063\tPosition before read 2019\n10:03:19.131\tCalling limit on byteBuffer with position 3306\n\n10:03:19.132\tBefore fill(): parsingHeader: [false], parsingRequestLine: [false], parsingRequestLinePhase: [0], parsingRequestLineStart: [0], byteBuffer.position(): [3306], byteBuffer.limit(): [3306], end: [2019]\n10:03:19.132\tSet mark at position 2019\n10:03:19.132\tPosition before read 2019\n10:03:19.244\tCalling limit on byteBuffer with position 3306\n\n10:03:19.245\tBefore fill(): parsingHeader: [false], parsingRequestLine: [false], parsingRequestLinePhase: [0], parsingRequestLineStart: [0], byteBuffer.position(): [3306], byteBuffer.limit(): [3306], end: [2019]\n10:03:19.245\tSet mark at position 2019\n10:03:19.245\tPosition before read 2019\n10:03:19.854\tEncountered exception in read during fill, position=0\n                j.n.c.AsynchronousCloseException: null\n                    at s.n.c.UnixAsynchronousSocketChannelImpl.finishRead(Unknown Source)\n                    at s.n.c.UnixAsynchronousSocketChannelImpl.finish(Unknown Source)\n                    ... 2 frames excluded\n                    at o.apache.tomcat.util.net.Nio2Channel.close(Nio2Channel.java:81)\n                    at o.apache.tomcat.util.net.Nio2Channel.close(Nio2Channel.java:94)\n                    at o.a.t.u.n.Nio2Endpoint$Nio2SocketWrapper.doClose(Nio2Endpoint.java:935)\n                    at o.a.t.util.net.SocketWrapperBase.close(SocketWrapperBase.java:422)\n                    at o.a.t.u.n.Nio2Endpoint$SocketProcessor.doRun(Nio2Endpoint.java:1685)\n                    at o.a.t.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\n                    at o.a.tomcat.util.net.AbstractEndpoint.processSocket(AbstractEndpoint.java:1171)\n                    at o.a.t.u.n.Nio2Endpoint$Nio2SocketWrapper$2.completed(Nio2Endpoint.java:613)\n                    at o.a.t.u.n.Nio2Endpoint$Nio2SocketWrapper$2.completed(Nio2Endpoint.java:591)\n                    ... 3 frames excluded\n                    at o.a.t.u.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)\n                    at o.a.t.u.t.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)\n                    at o.a.t.u.t.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n                    ... 1 frames excluded\n10:03:19.854\tCalling limit on byteBuffer with position 0\n\nSo, the java.nio.channels.AsynchronousCloseException thrown presumably from\nsocketWrapper.read leaves the byteBuffer with position=0. So the limit is\nset to 0 in the finally block, which sets the mark to -1, as its larger than\nthe limit (it was 2019 according to logs). Here's the snippet for Buffer.limit:\n\npublic Buffer limit(int newLimit) {\n    if (newLimit > capacity | newLimit < 0)\n        throw createLimitException(newLimit);\n    limit = newLimit;\n    if (position > newLimit) position = newLimit;\n    if (mark > newLimit) mark = -1;\n    return this;\n}\n\nThis in turn makes the reset() call fail\non the byte buffer as the mark is invalid.\n\nI've also observed that the above logs are sometimes missing\nthe \"Received\" log. I assume that this is swallowed by my\nlogging consumer as either the message is too large or the \"raw\nbytes\" make it choke. But I think that shouldn't worry us now!\n\nNow the question is: Is this really a bug in Tomcat? Do you agree that\nthe limit(0) call above should not happen? Is it reasonable that a thread\ninterruption could lead to the observed AsynchronousCloseException above?\n\nI've tried to reproduce it locally, but currently I can only observe\nit on a production system. I appreciate hints what could be going on or\nhow one could try to reproduce this within a more isolated environment.\n\nLet me know if you need further information.",
    "creation_ts": "2021-11-10T10:39:16Z",
    "fixes": [
      65677
    ],
    "comments": [
      "The runtime where this was observed is (it's a dockerized Spring Boot 2.5.6 application):\n\njava -version\nPicked up JAVA_TOOL_OPTIONS: -XX:MinRAMPercentage=75 -XX:MaxRAMPercentage=75 -XX:-OmitStackTraceInFastThrow -XX:+ExitOnOutOfMemoryError\nopenjdk version \"11.0.13\" 2021-10-19 LTS\nOpenJDK Runtime Environment 21.10-(Zulu-11.52+13-linux_x64)-Microsoft-Azure-restricted (build 11.0.13+8-LTS)\nOpenJDK 64-Bit Server VM 21.10-(Zulu-11.52+13-linux_x64)-Microsoft-Azure-restricted (build 11.0.13+8-LTS, mixed mode)",
      "Thanks for the report and the analysis. It is rather odd that the position gets set to zero but fixing it is relatively simple.\n\nFixed in:\n- 10.1.x for 10.1.0-M8 onwards\n- 10.0.x for 10.0.14 onwards\n- 9.0.x for 9.0.56 onwards\n- 8.5.x for 8.5.74 onwards"
    ]
  },
  {
    "id": 66084,
    "summary": "bytesWritten in writeBytes() miscalculation for OutputBuffer",
    "description": "Created attachment 38301\nleft is source code, right is test code\n\n\u5728org.apache.catalina.connector.OutputBuffer\u7c7b\u7684private void writeBytes(ByteBuffer from) \u65b9\u6cd5\u4e2d\uff0c\u4e0d\u80fd\u6b63\u786e\u7684\u5c06\u53ef\u5199\u5165\u5b57\u8282\u957f\u5ea6\u8ba1\u5165\u5199\u5165\u5b57\u8282\u6570\u636e\u603b\u91cf\u4e2d\u3002\n\nIn org. Apache. Catalina. Connector. OutputBuffer class private void writeBytes (ByteBuffer from) method, is unable to correctly write bytes will be recorded in writing bytes of data amount. -By translation software",
    "creation_ts": "2022-05-24T01:51:14Z",
    "fixes": [
      66084
    ],
    "comments": [
      "I've raised a pr based on your feedback, https://github.com/apache/tomcat/pull/516",
      "Fixed in:\n- 10.1.x for 10.1.0-M16 onwards\n- 10.0.x for 10.0.22 onwards\n- 9.0.x for 9.0.64 onwards\n- 8.5.x for 8.5.80 onwards"
    ]
  },
  {
    "id": 61086,
    "summary": "Some clients hang when HTTP responses give status 205 Reset Content",
    "description": "Created attachment 34992\nExemple standalone servlet to give out HTTP 205 response\n\nWhen a servlet running on Tomcat sends a response over HTTP with status 205 Reset Content, some clients hang with this response and just wait for it to \"complete\" after Tomcat considers it fully done.\n\nSo far I've identified two clients:\n- command line program curl, version 7.52.1,\n- Jersey client, version 1.19.1.\n\nUsing Tomcat 8.5.15 (latest release), but the issue was here for as long as I went back and it seems still here in Tomcat 9.\n\nDebugging the HTTP communication shows it has to do with the fact that the response has no body (which is correct, as mandated by RFC for status 205), and no indication of content length to explicitly say that there is no body. That last part is incorrect behavior according to RFC 7231 section 6.3.6:\n\n   \" Since the 205 status code implies that no additional content will be provided, a server MUST NOT generate a payload in a 205 response.  In other words, a server MUST do one of the following for a 205 response: a) indicate a zero-length body for the response by including a Content-Length header field with a value of 0; b) indicate a zero-length payload for the response by including a Transfer-Encoding header field with a value of chunked and a message body consisting of a single chunk of zero-length; or, c) close the connection immediately after sending the blank line terminating the header section. \"\n\nIt seems the HTTP clients I've identified, do rely on this requirement stated by RFC. Testing with servers that do add a Content-Length: 0 header or a Transfer-encoding chunked with a zero-length chunk with a status 205, these clients behave as expected. Also note, that Tomcat will typically eventually reach its keep-alive timeout and close the connection. Which is actually a valid way to end the response, and these clients do accept it when they don't reach their own timeouts. It's just the response takes by default 20 seconds to be finished, and is done with closing a perfectly re-usable connection.\n\nSteps to reproduce:\n\n (1) Have a clean Tomcat install version 8.5.15\n\n (2) Deploy on it a root webapp that responds to requests with\n     HTTP status 205.\n\n     You can use the standalone servlet class I put in attachment.\n     As can be seen, it responds to all requests with status 205,\n     and it adds a custom header just to be sure the response comes\n     from this servlet.\n\n (3) Make an HTTP request to it with curl.\n\n     Response looks like:\n\n$ curl -v http://localhost:8080\n* STATE: INIT => CONNECT handle 0x6000578f0; line 1413 (connection #-5000)\n* Rebuilt URL to: http://localhost:8080/\n* Added connection 0. The cache now contains 1 members\n*   Trying 127.0.0.1...\n* TCP_NODELAY set\n* STATE: CONNECT => WAITCONNECT handle 0x6000578f0; line 1466 (connection #0)\n* Connected to localhost (127.0.0.1) port 8080 (#0)\n* STATE: WAITCONNECT => SENDPROTOCONNECT handle 0x6000578f0; line 1583 (connection #0)\n* Marked for [keep alive]: HTTP default\n* STATE: SENDPROTOCONNECT => DO handle 0x6000578f0; line 1601 (connection #0)\n> GET / HTTP/1.1\n> Host: localhost:8080\n> User-Agent: curl/7.52.1\n> Accept: */*\n>\n* STATE: DO => DO_DONE handle 0x6000578f0; line 1680 (connection #0)\n* STATE: DO_DONE => WAITPERFORM handle 0x6000578f0; line 1807 (connection #0)\n* STATE: WAITPERFORM => PERFORM handle 0x6000578f0; line 1817 (connection #0)\n* HTTP 1.1 or later with persistent connection, pipelining supported\n< HTTP/1.1 205\n< x-mmar-servletname: return205\n< Date: Thu, 11 May 2017 15:43:26 GMT\n* no chunk, no close, no size. Assume close to signal end\n* Marked for [closure]: HTTP: No end-of-message indicator\n<\n* STATE: PERFORM => DONE handle 0x6000578f0; line 1981 (connection #0)\n* multi_done\n* Curl_http_done: called premature == 0\n* Closing connection 0\n* The cache now contains 0 members\n\n     curl hangs for a while after \"Marked for [closure]: HTTP: No end-of-message indicator\".\n     Then after 20 seconds Tomcat reaches connection\n     keep-alive timeout, closes the connection and curl\n     accepts it as a valid way to finish the response.\n\nProposed (naive) patch:\n\nI have located the cause for this behavior, in class\norg.apache.coyote.http11.Http11Processor\nin line 1144.\nStatus 205 is treated the same way as 204 and 304,\nthat is to say no body as mandated by RFC,\nbut also no content length information.\n\nThe naive patch attached just removes 205 from those,\nwhich solves the issue with the problematic clients.\nHowever it makes it possible to add a body to a\n205 response, and it becomes the webapp's author's\nresponsibility to not do that.\n\nAnother, possibly better, approach, could be to\nhave a special case for 205 only, where it\nwould ignore any attempt to put a content,\nbut it would add the header Content-Length: 0.",
    "creation_ts": "2017-05-11T20:29:50Z",
    "fixes": [
      61086
    ],
    "comments": [
      "Created attachment 34993\nNaive patch to remove 205 from the status without content",
      "Thanks for the report.\n\nThis has been fixed by explicitly setting content length to zero for 205 responses.\n\nThis has been fixed in:\n- 9.0.x for 9.0.0.M22 onwards\n- 8.5.x for 8.5.16 onwards\n- 8.0.x for 8.0.45 onwards\n- 7.0.x for 7.0.79 onwards",
      "Still reproducable on 8.5.16-19.\n\norg.apache.coyote.http11.Http11Processor\n...\n1129 entityBody = false;\n1130 contentDelimitation = true;\n1131 if (statusCode == 205) {\n1132    // RFC 7231 requires the server to explicitly signal an empty\n1133    // response in this case\n1134    response.setContentLength(0);\n1135 }\n...\n1166 if (!entityBody) {\n1167    response.setContentLength(-1);\n1168 }\n \nExplicitly setting contentLength(0) in 1134 overrides by 1167, so response doesn't contain Content-Length header.",
      "Created attachment 35175\nPatch 0-length content for 205 status",
      "Hi,\n\n(In reply to Alexandr Saperov from comment #4)\n> Created attachment 35175 [details]\n> Patch 0-length content for 205 status\n\nWould you mind to add a test case also?\n\nThanks,\nVioleta",
      "Created attachment 35179\nstandalone application with embedded tomcat\n\nBuilding standalone application with embedded tomcat:\nmvn clean package\n\nrunning application:\njava -jar target/tomcat-61086-1.0-SNAPSHOT.jar\n\nMaking request with curl:\ncurl -v \"localhost:8080/\"\n\ncurl hangs for 1 minute (default timeout)",
      "Hi,\n\nThanks for the patch and the test - see r1803616.\n\nThis has been fixed in:\n- 9.0.x for 9.0.0.M26 onwards\n- 8.5.x for 8.5.20 onwards\n- 8.0.x for 8.0.46 onwards\n- 7.0.x for 7.0.80 onwards\n\nRegards,\nVioleta"
    ]
  },
  {
    "id": 65770,
    "summary": "Make keys reload automatically",
    "description": "Functionality like in\nhttps://github.com/schnatterer/tomcat-reloading-connector\nwould be a great help for those who use APR and Letsencrypt\n\nIt should presumably be an optional feature enabled by an attribute.",
    "creation_ts": "2021-12-28T08:21:39Z",
    "fixes": [
      65770
    ],
    "comments": [
      "I'm not sure it is a very good idea to use an automagical reload here. There is functionality to trigger a reload of the SSL host configs using JMX, this is more predictable. Is it not a good solution for you ?\n\nIf you still want this, then you can write a custom Server listener, that uses the Tomcat background process feature (this avoids having a dedicated thread) to monitor the resources you want to check, and that would call the reload hook (either normally or through JMX).",
      "Since administrating SSL certificates is a major PITA, I'm looking for a built-in solution that is compatible with ACME.\n\nFor my current use I will use: https://github.com/schnatterer/tomcat-reloading-connector.\n\nIf there are other ways to achieve this functionality without having OS-specific scripts, that would be fine as well.\n\nThe most popular solution seems to put another Web server in front of Tomcat.  Although certainly doable, this adds more complexity.",
      "I think there is an argument for providing a listener to do this as part of the Tomcat distribution. Those users that need it can then enable it.",
      "Stupid question: Why is it not possible to use the background process to detect mtime change of cert/private key and initiate a connector reload? This would be, of course, off by default.",
      "(In reply to Michael Osipov from comment #4)\n> Why is it not possible to use the background process to\n> detect mtime change of cert/private key and initiate a connector reload?\n\nIt is possible. It's best done using a Listener (or maybe a Valve?) with a background process.\n\nAnother option would be to use Romain Manni-Bucau's complete ACME component within Tomcat. It handles the whole ACME process, including reloading the connector as necessary.\n\nThe OP recommends using a package that is limited (APR only), fragile (custom non-daemon watcher thread, suspicious call behavior, and (IMHO) unnecessary.",
      "> The OP recommends using a package that is limited (APR only), fragile\n> (custom non-daemon watcher thread, suspicious call behavior, and (IMHO)\n> unnecessary.\n\nI'm merely proposing adding this kind of functionality.  I'm not an expert on Tomcat internals so I have no suggestion on how :)\n\n> Another option would be to use Romain Manni-Bucau's complete ACME component\n> within Tomcat. It handles the whole ACME process, including reloading the\n> connector as necessary.\n\nAlthough I was unaware of Romain's ACME stuff, I'm a little bit worried about scoping key reload exclusively to ACME.  In addition there are several external ACME packages like https://certbot.eff.org/ which are designed to work with arbitrary Web servers.  I'm currently using certbot and the mentioned custom APR connector.",
      "I'd also say that any form of automatic reloading (e.g. via fnotify on respectively periodic reloading of the cert/key files) is a bad idea.\nIt may e.g just happen at the time where only one of the two has already been replaced.\n\nInstead, I've asked in bug #66526 for a way to *only* reload key/certificate files - not any other configuration.\n\nSuch a feature should be easily usable with e.g. certbot and friends.",
      "I've been discussing this with the users recently and came up with the following approach.\n\n- Lifecycle listener that ships with Tomcat\n- Every X minutes (driven by background process but customisable so checks don't happen every time the background process runs)\n- Checks expiry time of each cert.\n- For each cert with less than Y days reload TLS config\n- If cert still has less than Y days remaining, log a warning\n\nThis listener would be disabled by default but available as part of the standard Tomcat distribution.",
      "(In reply to Mark Thomas from comment #8)\n> I've been discussing this with the users recently and came up with the\n> following approach.\n> \n> - Lifecycle listener that ships with Tomcat\n> - Every X minutes (driven by background process but customisable so checks\n> don't happen every time the background process runs)\n> - Checks expiry time of each cert.\n> - For each cert with less than Y days reload TLS config\n\nWhy have this \"must be less than Y days-to-expiration\" predicate? Why not just always-reload if e.g. the source timestamp has changed? There are many reasons to swap-out certificates that are not expiring.\n\nWe probably should make sure the file is at least X ms old to prevent trying to reload a file that it in the process of being re-written.\n\n> - If cert still has less than Y days remaining, log a warning\n\nI think this will fill the logs.",
      "Not every key/cert is defined by a file.\n\nAt least one cloud provider (Azure) has a JCA provider that enables Java apps to access keys in the cloud provided vault without any reference to a file on the file system. Support for certificateKeystoreFile to accept \"\" or \"NONE\" was implemented for hardware keystores. Without access to a file, a way to determine when to trigger the reload was required. Given this listener is intended for systems that have automated key updates, X days before current key expiry was a simple trigger that worked for all the scenarios. Happy to consider alternatives if someone has a better idea.\n\nThe logging was intended to be annoying. If you have a system that is meant to automatically updates your TLS keys then a noisy log message when that system fails seems reasonable to me. Thinking about it, you will want a log message when TLS reloading is triggered so there is going to be a log message anyway. There is probably some fine tuning to do once the first draft of this is implemented.",
      "(In reply to Mark Thomas from comment #8)\n> I've been discussing this with the users recently and came up with the\n> following approach.\n> \n> - Lifecycle listener that ships with Tomcat\n> - Every X minutes (driven by background process but customisable so checks\n> don't happen every time the background process runs)\n> - Checks expiry time of each cert.\n> - For each cert with less than Y days reload TLS config\n> - If cert still has less than Y days remaining, log a warning\n> \n> This listener would be disabled by default but available as part of the\n> standard Tomcat distribution.\n\nGood feature.",
      "(In reply to Mark Thomas from comment #8)\n> I've been discussing this with the users recently and came up with the\n> following approach.\n> \n> - Lifecycle listener that ships with Tomcat\n> - Every X minutes (driven by background process but customisable so checks\n> don't happen every time the background process runs)\n> - Checks expiry time of each cert.\n> - For each cert with less than Y days reload TLS config\n> - If cert still has less than Y days remaining, log a warning\n> \n> This listener would be disabled by default but available as part of the\n> standard Tomcat distribution.\n\nMaybe this listener should receive a reload interface will will decide whether the file needs to be reloaded or not? We can provide a default impl, but others can implement their logic?!",
      "(In reply to Michael Osipov from comment #12)\n> Maybe this listener should receive a reload interface will will decide\n> whether the file needs to be reloaded or not? We can provide a default impl,\n> but others can implement their logic?!\n\nThere's already a JMX command for reload though.",
      "Fixed in:\n- 11.0.x for 11.0.0-M12 onwards\n- 10.1.x for 10.1.14 onwards\n-  9.0.x for  9.0.81 onwards\n-  8.5.x for  8.5.94 onwards"
    ]
  },
  {
    "id": 42753,
    "summary": "Race condition when using available() or reading in CometProcessor.event()",
    "description": "Tomcat version: 6.0.13 (no 6.0.13 available in the version field)\n\nWhen trying to process data in CometProcessor.event() either during the BEGIN\nevent or during the READ event, it is impossible to guarantee that all data has\nbeen read before returning (since new data may arrive between the last statement\nbefore the return, and the return statement itself). However, the\nCoyoteProcessor does this check:\n\n } else if (!error && read && request.getAvailable()) {\n    // If this was a read and not all bytes have been read, or if no data\n    // was read from the connector, then it is an error\n    error = true;\n    log.error(sm.getString(\"coyoteAdapter.read\"));\n } \n\ncausing a severe error and the Comet request to break when this race condition\nmanifests itself.\n\nI am using the following code according to the aio.html description to read data\nin my comet event handler:\n\n  while (request.getInputStream().available() > 0) {\n     // read some data\n  }\n  // ***** NO MORE DATA AVAILABLE\n  return;\n\nAnd I am experiencing the error as described in certain conditions (rapid\narrival of fragmented data):\n\nSEVERE: The servlet did not read all available bytes during the processing of\nthe read event",
    "creation_ts": "2007-06-27T05:21:53Z",
    "fixes": [
      42753
    ],
    "comments": [
      "available() does not make any socket access to see if bytes have arrived, so the\nscenario you describe cannot happen (if available returns 0, it will continue\nreturning 0 until the next read event). If the message you saw is logged,\nCometAdapter.event will return false, which will lead to closing the connection,\nnot causing a loop.\n\nMy only theory is that you're doing asynchronous reads, which is not allowed,\nand you'll need to look into this further.\n\nWhat does \"(no 6.0.13 available in the version field)\" mean ?",
      "I have very explicit logging and I'm 100% certain that I'm not doing any async\nreads. In fact, from the log I sent to the user list before reporting this as a\nbug you can see that everything is happening in 1 thread, namely http-8080-exec-4:\n\n2007-06-26 14:37:08,427 DEBUG [http-8080-exec-4]\ncom.sebster.myservlet.TomcatCometServlet - BEGIN event for request\norg.apache.catalina.connector.RequestFacade@d47c99\n2007-06-26 14:37:08,427 DEBUG [http-8080-exec-4]\ncom.sebster.myservlet.TomcatCometServlet - 127.0.0.1:60578 POST /mycometservlet\n2007-06-26 14:37:08,432 DEBUG [http-8080-exec-4]\ncom.sebster.myservlet.TomcatCometServlet -\n[24224039-a37e-40d0-a076-89d1df363390] read loop in BEGIN event, input stream\ndata available: 1\n2007-06-26 14:37:08,438 DEBUG [http-8080-exec-4]\ncom.sebster.myservlet.TomcatCometServlet -\n[24224039-a37e-40d0-a076-89d1df363390] read loop done, input stream data\navailable: 0\n2007-06-26 2:37:08.MD org.apache.catalina.connector.CoyoteAdapter event\nSEVERE: The servlet did not read all available bytes during the processing of\nthe read event\n\nNote that I'm not implying that available() does a socket access; what I saw was\nthat when the loop I described in the original post ended the condition\n\"available() == 0\" was true, and when it got to CatalinaAdapter the condition\nRequest.getAvailable() was true.\n\nFuthermore, I really am seeing the loop without the connection being closed,\nboth on the windows platform and on the Linux platform. I'm happy to help debug\nthis further, but I'm not making it up: I have a breakpoint in my\nCometProcessor.event() method, I see the Poller thread spin like crazy, and when\nI set a break point in the Poller the CPU load goes away. I can step through it\nand see that the connection stays open, it sets the event type to END on the\ncomet event, but it never reaches my CometProcessor.event() method.\n\nFinally, what I mean with \"no 6.0.13 available in the version field\" is the\ndropdown box in which to mark the Tomcat version in the bugzilla bug form. It\ngoes up to and including 6.0.11.\n\nRegards,\nSebastiaan",
      "Since you're apparently not willing to write things that make sense, I will\nignore your report.",
      "(In reply to comment #3)\n> Since you're apparently not willing to write things that make sense, I will\n> ignore your report.\n\nI am getting really exasperated by your replies. You give me no hint at what it\nis you want or what you think is not making sense. I will test your theory more\nby writing a wrapper around the input stream to log the thread of every read\nthat happens just to make sure tomorrow.\n\nIn either case, after I got the error the Poller went into a busy loop. I'm not\nsmoking pot and I saw what I saw. Ok, maybe there's a bug somewhere in my code\nand I'm doing something wrong, I certainly don't want to exclude that\npossibility. But I saw the Poller go into an infinite loop (not caused by the\nNIO bug I was talking about previously (which is Linux only)). It did NOT close\nthe channel. It did NOT call my event method with a READ, ERROR or END event\n(which I know because I have a log.debug on enter, AND a break point set). This\nhappened directly AFTER I got the SEVERE log message. I got this on Windows and\nLinux. Note that I'm not theorizing now, these are the raw observations.",
      "If you follow the code logic, if the error happens, where available() returns >0\nafter a READ has been invoked, the connection is never marked as a comet, so you\nwill not get the ERROR/END events invoked. so the connection goes into the\npoller for the next request.\nCould you see if you can work up a reproducible scenario, and we can take it\nfrom there.",
      "(In reply to comment #5)\n> If you follow the code logic, if the error happens, where available() returns >0\n> after a READ has been invoked, the connection is never marked as a comet, so you\n> will not get the ERROR/END events invoked. so the connection goes into the\n> poller for the next request.\n> Could you see if you can work up a reproducible scenario, and we can take it\n> from there.\n\nWhen I look in the code I see the following:\n\n                if (response.isClosed() || !request.isComet()) {\n                    res.action(ActionCode.ACTION_COMET_END, null);\n                } else if (!error && read && request.getAvailable()) {\n                    // If this was a read and not all bytes have been read, or\nif no data\n                    // was read from the connector, then it is an error\n                    error = true;\n                    log.error(sm.getString(\"coyoteAdapter.read\"));\n                }\n                return (!error);\n\nSo when you get the error, the condition response.isClosed() ||\n!request.isComet() must evaluate to false, which means that !response.isClosed()\n&& request.isComet(). So for me to get the error it seems the request must\nalready be marked as a comet request.\n\nI am not able to give you a small test case. The problem is that I have two\ndifferent products that start an embedded tomcat using exactly the same class,\nand in one it consistently works (no errors whatsoever), and in the other it\nconsistently fails. I have not seen this issue before (and I have already done a\nlot of testing in different situations), and I have no idea what the\nprecondition is for this issue to manifest itself.\n\nHowever, I added extra debugging information, and I did find something strange.\nI do the following logging FIRST thing in my Comet processor and I wrapped the\ninput stream to log which thread does the reading:\n\n  final EventType eventType = event.getEventType();\n  if (Debug.ENABLED && logger.isDebugEnabled()) {\n    try {\n      final Field field = request.getClass().getDeclaredField(\"request\");\n//$NON-NLS-1$\n      field.setAccessible(true);\n      final Request internalRequest = (Request) field.get(request);\n      logger.debug(\"{} event for request facade {}, request {}\", new Object[] {\neventType, request, internalRequest }); //$NON-NLS-1$\n    } catch (final Exception e) {\n      logger.debug(\"{} event for request facade {}\", eventType, request);\n//$NON-NLS-1$\n      logger.debug(\"failed to get request\", e); //$NON-NLS-1$\n    }\n  }\n\nI set a breakpoint in the CoyoteAdapter where it gives the SEVERE error, looked\nat the id of the request object, and checked my log what events I got for that\nobject.\n\nMy results where as follows:\n\n2007-06-28 11:16:00,021 DEBUG [http-8080-exec-4]\ncom.sebster.myservlet.MyCometServlet - BEGIN event for request facade\norg.apache.catalina.connector.RequestFacade@1dc696e, request\norg.apache.catalina.connector.Request@18dbef1\n\nThis was the ONLY line in the log with Request@18dbef1. All the reads in this\nBEGIN event happen on the http-8080-exec-4 thread. After returning from the read\n(due to available() == 0), it immediately stops in my breakpoint in\nCoyoteAdapter to log the SEVERE error. Note that I first set the break point to\nfind the id of the Request object to look for in the log.\n\nThe strange thing is, that the breakpoint happens in the http-8080-exec-5\nthread. The comet field in the Request@1dc696e object is set to true, and\nrequest.getAvailable() also returns true.\n\nThese are my observations so far. Note that I am no expert on Tomcat internals,\nbut I am very willing to spend time on this issue to resolve it, so any tips,\nsuggestions, questions, or assignments :-) are welcome!\n\nTo summarize:\n1) I get a BEGIN event for Request@1dc696e in http-8080-exec-4\n2) I read until available() == 0 in http-8080-exec-4\n3) I return from the event() method in http-8080-exec-4\n4) Tomcat logs a SEVERE error stating that I have not read all data\n     * The request object is Request@1dc696e\n     * request.isComet() == true\n     * request.getAvailable() == true\n     * the thread is http-8080-exec-5\n     * at this point there are zero log lines for thread http-8080-exec-5\n\nRegards,\nSebastiaan",
      "I did some additional debugging on the Poller loop that occurs after the SEVERE\nerror. This is what happens:\n\n1) the CoyoteAdapter.event() method gets called.\n2) request.read() returns false\n3) the condition status == SocketStatus.STOP evaluates to true\n4) the following statements are executed\n    request.getEvent().setEventType(CometEvent.EventType.END);\n    request.getEvent().setEventSubType(CometEvent.EventSubType.SERVER_SHUTDOWN);\n5) in the following statement getFirst() returns the \"basic\" field, a\nStandardEngineValve:\n    connector.getContainer().getPipeline().getFirst().event(request, response,\nrequest.getEvent());\n6) my CometProcessor.event() method is NOT called\n7) error = false, and the event() method returns true\n\nThis loop repeats ad infinitum, and consumes 100% CPU. Note that no code of my\nown is called in this sequence.\n\nRegards,\nSebastiaan",
      "I just wrote a simple test client that doesn't read the contents and I\nexperienced no loop. END nor ERROR got called, so there is a problem here, the\ncontainer should call one of those methods.\nare you able to test your solution against the latest\ntc6.0.x branch as well as the trunk branch?",
      "(In reply to comment #8)\n> I just wrote a simple test client that doesn't read the contents and I\n> experienced no loop. END nor ERROR got called, so there is a problem here, the\n> container should call one of those methods.\n> are you able to test your solution against the latest\n> tc6.0.x branch as well as the trunk branch?\n\nA patch for the END/ERROR never being called has been submitted to both 6.0.x\nand trunk. This should at least give you a chance to cleanup, \n\nyour original problem of available()==0 but there yet being data, causing an\ninfinite loop is to me non reproducible.\n\nI'll wait for your feedback before marking this fixed.",
      "(In reply to comment #9)\n\n> A patch for the END/ERROR never being called has been submitted to both 6.0.x\n> and trunk. This should at least give you a chance to cleanup, \n\nThanks :-), I will test this ASAP.\n\n> your original problem of available()==0 but there yet being data, causing an\n> infinite loop is to me non reproducible.\n\nThe main clue (as far as I can tell) of something going wrong is the fact that\nthe BEGIN event + read loop is in 1 thread, and the error in happens another\n(see the summary of comment 6). Do you not agree that this should not happen? If\nyou agree that this is wrong (whatever the cause, Tomcat or my code), I can try\nand debug what causes this to happen.\n\nRegards,\nSebastiaan",
      "Once the socket goes back to the poller, and the poller dispatches it again,\nthen that can be on a different thread, as tomcat uses a thread pool, so there\nis no guarantee what thread the poller dispatches too",
      "(In reply to comment #11)\n> Once the socket goes back to the poller, and the poller dispatches it again,\n> then that can be on a different thread, as tomcat uses a thread pool, so there\n> is no guarantee what thread the poller dispatches too\n\nYes I understand that, but for the specific Request object instance I get only 1\ncomet event, in thread http-8080-exec-4 and the check of Request.getAvailable()\nto see if I read everything happens in http-8080-exec-5 (with no other comet\nevents in between - I ONLY get the BEGIN event for this Request instance). Is\nthis not strange? Should the check not be performed in the same thread before\nthe socket goes back to the poller?",
      "not really, getAvailable() is only called if read() returned true.\nin your case, the following might happen\n1. HTTP request comes in, no body\n2. You get BEGIN event, no additional data on the socket\n3. read() returns false, so you dont get an immediate READ event,",
      "I have found the cause of the problem.\n\nThe code place where it goes wrong is ApplicationFilterFactory line 126:\n\n            Request req = (Request) request;\n            if (Globals.IS_SECURITY_ENABLED) {\n                // Security: Do not recycle\n                filterChain = new ApplicationFilterChain();\n            } else {\n                filterChain = (ApplicationFilterChain) req.getFilterChain();\n                if (filterChain == null) {\n                    filterChain = new ApplicationFilterChain();\n                    req.setFilterChain(filterChain);\n                }\n            }\n            comet = req.isComet();\n\nWhen a security manager is installed the filter chain is not set on the request.\n\nOn subsequent Comet events, since the filter chain is null, the event is not\nhandled properly and the poller goes into a busy loop.",
      "Excellent, we will fix this!",
      "The \"issue\" in this bug report is that the user claims that the value of\n\"available()\" randomly changes. This minor glitch is unrelated.",
      "(In reply to comment #16)\n> The \"issue\" in this bug report is that the user claims that the value of\n> \"available()\" randomly changes. This minor glitch is unrelated.\n\nThe issue was that Tomcat reported that I had not read all available bytes even\nthough I did. The reason turns out to be because Tomcat was not calling the\nevent method of my comet processor, which entails that indeed bytes were not\nbeing read.\n\nMy original issue is thereby resolved and the summary of this bug turns out to\nbe wrong. It just looked to me like there was a race condition, since I had a\nbreakpoint in event() and it was not being called anymore, so I thought\n(erroneously) that it was complaining at the end of the BEGIN event.\n\nSo, as far as I'm concerned this issue can be closed. I don't care if you mark\nit INVALID if that's what you want because the summary turns out to be\nincorrect; that's fine by me.\n\nI'm happy that the issue is resolved and the bug is fixed. :-)",
      "(In reply to comment #15)\n> Excellent, we will fix this!\n\nThanks a lot. :-) Sorry for my initially incorrect analysis of the problem. I\nshould stick to reporting observed behavior instead of theorizing."
    ]
  },
  {
    "id": 69338,
    "summary": "Overhead in El processing (AST*)",
    "description": "Created attachment 39873\nSpeed test\n\nI received a report of a minor change to an EL expression causing a latency penalty and, upon investigation, discovered some ways to simplify the execution and reduce the effort required to evaluate EL.  I'm not convinced the report was accurate but these are nevertheless good changes.\n\nThe specific change was adding a branch to an if statement, along these lines:\n\n<c:if test=\"${not empty myNewAttribute\n                && existingClause1\n                && existingClause2\n                && existingClause3\n                && existingClause4}\">\n\n              \n\nFirst - the expression \"${not empty myNewAttribute}\" is turned into five Node instances: AstCompositeExpression, AstDynamicExpression, AstNot, AstEmpty, and AstIdentifier. As noted previously, each call to getValue() on each node triggers a virtual method lookup, so is more expensive than it looks.  Three of the Nodes also rely on type coercion (AstCompositeExpression, AstNot, AstEmpty).  Small EL changes such as the report I received can increase this node depth and therefore noticeably increase the EL processing time.  Suggestion: create an AstNotEmpty node to handle the frequent case of ${not empty <whatever>}.  This will eliminate one Node and only attempt one Boolean coercion rather than two.\n\nSecond - the use of multiple \"&&\" clauses results in a series of nested AstAnd.  Each instance adds its own overhead and produces its own Boolean result... and each parent AstAnd coerces that Boolean into another Boolean.  A more-than-binary AstAnd would eliminate several layers of Nodes and the associated coercion.\n\nI've attached the usual standalone perf test, demonstrating a 25% deceleration when the extra statement is added.  This is linear and therefore expected... however the test is unusually memory sensitive (I run it with -Xmx3g) so there may be some kind of effect there.\n\nI expect these changes to reduce the processing time of any EL expression with 2+ \"&&\" clauses, as well as any expression using \"not empty\".",
    "creation_ts": "2024-09-24T16:58:49Z",
    "fixes": [
      69338
    ],
    "comments": [
      "Created attachment 39874\nSupport class for the speed test",
      "The parser that produces the node structure is generated using JJTree and JavaCC. The starting point (for 9.0.x) is this file:\n\nhttps://github.com/apache/tomcat/blob/9.0.x/java/org/apache/el/parser/ELParser.jjt\n\nWhat impact the proposed changes have on expression parse time vs expression processing time is TBD since any change is likely to impact the parse time for every expression as well as the evaluation time.\n\nWe'll need to do some performance tests to confirm the benefits of each change.",
      "I've been looking at the handling for multiple && and ||. The performance numbers are clear it is worth doing. There is no noticeable change for 2 operands and obvious improvements from 3 operands upwards. The more operands, the clearer the benefit. At 10 operands the new approach is roughly twice as fast.\n\nI need to do some more testing to make sure the changes to the parser are correct. I should have something to commit for this tomorrow.",
      "I'd be interested in how you solved this particular problem, Mark.\n\nHaving written a DSL for $work using AntLR, we have this \"problem\" as well, where a string of the same binary operators end up being nested inside one another. For performance-critical uses, we have e.g. a \"sum\" function that can be used for 1+2+3+4+5 and both \"and\" and \"or\" functions for the obvious boolean combinations. That seemed easier than trying to tweak the parser to convert 1+2+3+4+5 into sum(1,2,3,4,5) instead of 1+(2+(3+(4+5))).",
      "I've tweaked the parser for AND and OR so it looks for two or more operands rather than just two.",
      "Fixed in:\n- 11.0.x for 11.0.0 onwards\n- 10.1.x for 10.1.31 onwards\n-  9.0.x for  9.0.96 onwards",
      "Thank you for the quick turnaround!  FWIW, the report I received is holding up, but there's also some internal code in the area.  I'll open a new ticket for anything else I stumble upon.",
      "These changes reached production and behaved as expected - the following Ast combinations are eliminated:\n\n- AstNot -> AstEmpty\n- AstAnd -> AstAnd\n- AstOr -> AstOr\n\nOur application's EL-related work appears to have decreased around 20%, although that number's dirty because of multiple optimizations in the same release.\n\nAt any rate, this is good.  :)"
    ]
  }
]